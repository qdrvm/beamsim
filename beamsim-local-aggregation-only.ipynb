{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2622e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import beamsim\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import current_thread\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Set seaborn style for beautiful plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "plt.rcParams[\"font.size\"] = 11\n",
    "\n",
    "# Default configuration parameters - single source of truth\n",
    "DEFAULT_CONFIG = {\n",
    "    'backend': 'ns3-direct',\n",
    "    'snark1_pull': True,\n",
    "    'snark1_half_direct': True,\n",
    "    'signature_half_direct': 0,\n",
    "    'shuffle': False,\n",
    "    'random_seed': 42,\n",
    "    'group_count': 8,\n",
    "    'group_validator_count': 1024,\n",
    "    'group_local_aggregator_count': \"10%\",  # Default to 10% of group validators\n",
    "    'global_aggregator_count': 102,\n",
    "    'mesh_n': 8,\n",
    "    'non_mesh_n': 4,\n",
    "    'idontwant': False,\n",
    "    'signature_time': '20ms',\n",
    "    'signature_size': 3072,\n",
    "    'snark_size': 131072,\n",
    "    'snark1_threshold': 0.9,\n",
    "    'snark2_threshold': 0.66,\n",
    "    'aggregation_rate_per_sec': 1000,\n",
    "    'snark_recursion_aggregation_rate_per_sec': 10,\n",
    "    'pq_signature_verification_time': '30us',\n",
    "    'snark_proof_verification_time': '5ms',\n",
    "    'gml': 'shadow-atlas.bin',\n",
    "    'max_bitrate': '50Mbps'  # Default EIP-7870 bandwidth limit\n",
    "}\n",
    "\n",
    "\n",
    "def generate_yaml_config(topology=\"gossip\", **overrides):\n",
    "    \"\"\"\n",
    "    Generate a YAML configuration with default values and optional overrides.\n",
    "    \n",
    "    Args:\n",
    "        topology: Network topology (\"gossip\", \"grid\", etc.)\n",
    "        **overrides: Dictionary of parameter overrides\n",
    "        \n",
    "    Common override parameters:\n",
    "        - signature_size: Size of signatures in bytes\n",
    "        - max_bitrate: Bandwidth limit (e.g., \"10Mbps\" or None for unlimited)\n",
    "        - mesh_n: Gossip mesh_n parameter\n",
    "        - non_mesh_n: Gossip non_mesh_n parameter\n",
    "        - group_validator_count: Number of validators per group\n",
    "        - group_local_aggregator_count: Number of local aggregators per group\n",
    "        - group_count: Number of groups\n",
    "        - global_aggregator_count: Number of global aggregators\n",
    "        - snark1_threshold: Threshold for SNARK1 generation\n",
    "        - aggregation_rate_per_sec: Rate of signature aggregation\n",
    "        - random_seed: Random seed for reproducibility\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use default configuration and add topology, then apply overrides\n",
    "    defaults = DEFAULT_CONFIG.copy()\n",
    "    defaults['topology'] = topology\n",
    "    \n",
    "    # Apply overrides\n",
    "    config = {**defaults, **overrides}\n",
    "    \n",
    "    # Build the YAML string\n",
    "    yaml_content = f\"\"\"\n",
    "# Simulation Backend Configuration\n",
    "backend: {config['backend']}\n",
    "                                \n",
    "snark1_pull: {str(config['snark1_pull']).lower()}\n",
    "snark1_half_direct: {str(config['snark1_half_direct']).lower()}\n",
    "signature_half_direct: {str(config['signature_half_direct']).lower()}\n",
    "\n",
    "# Network Topology Configuration\n",
    "topology: {config['topology']}\n",
    "\n",
    "# Whether to shuffle validators from the same group to different routers\n",
    "shuffle: {str(config['shuffle']).lower()}\n",
    "\n",
    "# Seed for reproducible simulation results\n",
    "random_seed: {config['random_seed']}\n",
    "\n",
    "# Role Assignment Configuration\n",
    "roles:\n",
    "  group_count: {config['group_count']}\n",
    "  group_validator_count: {config['group_validator_count']}\n",
    "  group_local_aggregator_count: {config['group_local_aggregator_count']}\n",
    "  global_aggregator_count: {config['global_aggregator_count']}\n",
    "\n",
    "# Gossipsub Network Configuration\n",
    "gossip:\n",
    "  mesh_n: {config['mesh_n']}\n",
    "  non_mesh_n: {config['non_mesh_n']}\n",
    "  idontwant: {str(config['idontwant']).lower()}\n",
    "\n",
    "# Cryptographic Constants\n",
    "consts:\n",
    "  signature_time: {config['signature_time']}\n",
    "  signature_size: {config['signature_size']}\n",
    "  snark_size: {config['snark_size']}\n",
    "  snark1_threshold: {config['snark1_threshold']}\n",
    "  snark2_threshold: {config['snark2_threshold']}\n",
    "  aggregation_rate_per_sec: {config['aggregation_rate_per_sec']}\n",
    "  snark_recursion_aggregation_rate_per_sec: {config['snark_recursion_aggregation_rate_per_sec']}\n",
    "  pq_signature_verification_time: {config['pq_signature_verification_time']}\n",
    "  snark_proof_verification_time: {config['snark_proof_verification_time']}\n",
    "\n",
    "# Network Simulation Parameters\n",
    "network:\n",
    "  gml: \"{config['gml']}\"\n",
    "\"\"\"\n",
    "    \n",
    "    # Add bandwidth constraint if specified\n",
    "    if config['max_bitrate'] is not None:\n",
    "        yaml_content += f\"  max_bitrate: {config['max_bitrate']}\\n\"\n",
    "    \n",
    "    return beamsim.yaml(yaml_content.strip())\n",
    "\n",
    "\n",
    "# Worker function for parallel processing - using ThreadPoolExecutor instead of multiprocessing\n",
    "# to avoid pickle issues in Jupyter notebooks\n",
    "def _run_single_simulation_thread(topology, param_value, parameter_name, param_display, \n",
    "                                 config_overrides, run_kwargs, display_name, display_unit):\n",
    "    \"\"\"\n",
    "    Worker function to run a single configuration across multiple seeds in parallel context.\n",
    "    Runs the same configuration 5 times with different random_seed values and returns averaged metrics.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Determine seed values to use\n",
    "        base_seed = config_overrides.get('random_seed', DEFAULT_CONFIG.get('random_seed', 42))\n",
    "        seed_values = [base_seed + i for i in range(5)]\n",
    "\n",
    "        # Determine signature_half_direct for labeling (especially for grid)\n",
    "        sig_hd_for_display = None\n",
    "        if topology == 'grid':\n",
    "            if parameter_name == 'signature_half_direct':\n",
    "                sig_hd_for_display = param_value\n",
    "            elif 'signature_half_direct' in config_overrides:\n",
    "                sig_hd_for_display = config_overrides['signature_half_direct']\n",
    "            else:\n",
    "                sig_hd_for_display = DEFAULT_CONFIG.get('signature_half_direct', 0)\n",
    "\n",
    "        times_ms = []\n",
    "        dup_counts = []\n",
    "        dup_avgs = []\n",
    "        validator_count = None\n",
    "        snark1_threshold = None\n",
    "\n",
    "        for seed in seed_values:\n",
    "            # Create config with this parameter value and seed\n",
    "            current_config = {**config_overrides, parameter_name: param_value, 'random_seed': seed}\n",
    "            modified_yaml = generate_yaml_config(topology=topology, **current_config)\n",
    "\n",
    "            # Run simulation with modified config\n",
    "            current_run_kwargs = {**run_kwargs, 'c': modified_yaml}\n",
    "            items = beamsim.run(**current_run_kwargs, t=topology, local_aggregation_only=True)\n",
    "\n",
    "            # Extract SNARK1 timing information\n",
    "            snark1_sent = beamsim.get_snark1_sent(items)\n",
    "            if snark1_sent and len(snark1_sent[0]) > 0:\n",
    "                snark1_completion_time = snark1_sent[0][-1] if snark1_sent[0] else 0\n",
    "                times_ms.append(snark1_completion_time)\n",
    "\n",
    "                # Get simulation info (consistent across seeds)\n",
    "                _, _, validator_count, snark1_threshold, _ = beamsim.filter_report(items, \"info\")[0]\n",
    "\n",
    "                # Extract signature duplicate information (may be absent)\n",
    "                try:\n",
    "                    signature_duplicates, avg_duplicates = beamsim.get_signature_duplicates(items)\n",
    "                except Exception:\n",
    "                    signature_duplicates = 0\n",
    "                    avg_duplicates = 0.0\n",
    "                dup_counts.append(signature_duplicates)\n",
    "                dup_avgs.append(avg_duplicates)\n",
    "            # else: skip this seed if no data found\n",
    "\n",
    "        if len(times_ms) > 0:\n",
    "            # Determine topology display name - handle idontwant variants for gossip and sig_hd for grid\n",
    "            base_topology_display = \"gossipsub\" if topology == \"gossip\" else beamsim.topology_name.get(topology, topology)\n",
    "            if topology == 'grid' and sig_hd_for_display is not None:\n",
    "                topology_display = f\"{base_topology_display} (signature_half_direct={sig_hd_for_display})\"\n",
    "            elif \" (idontwant=\" in param_display and topology == \"gossip\":\n",
    "                if \"(idontwant=True)\" in param_display:\n",
    "                    topology_display = f\"{base_topology_display} (idontwant=True)\"\n",
    "                else:\n",
    "                    topology_display = f\"{base_topology_display} (idontwant=False)\"\n",
    "            else:\n",
    "                topology_display = base_topology_display\n",
    "\n",
    "            return {\n",
    "                'topology': topology,\n",
    "                'topology_display': topology_display,\n",
    "                'parameter_name': parameter_name,\n",
    "                'parameter_value': param_value,\n",
    "                'parameter_display': param_display,\n",
    "                'signature_half_direct': sig_hd_for_display,\n",
    "                # Average across seeds\n",
    "                'snark1_completion_time': float(np.mean(times_ms)),\n",
    "                'validator_count': validator_count,\n",
    "                'snark1_threshold': snark1_threshold,\n",
    "                'signature_duplicates': float(np.mean(dup_counts)) if dup_counts else 0.0,\n",
    "                'avg_signature_duplicates': float(np.mean(dup_avgs)) if dup_avgs else 0.0,\n",
    "                'num_seeds': len(times_ms),\n",
    "                'success': True\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'topology': topology,\n",
    "                'parameter_name': parameter_name,\n",
    "                'parameter_value': param_value,\n",
    "                'parameter_display': param_display,\n",
    "                'success': False,\n",
    "                'error': 'No SNARK1 data found across seeds'\n",
    "            }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'topology': topology,\n",
    "            'parameter_name': parameter_name,\n",
    "            'parameter_value': param_value,\n",
    "            'parameter_display': param_display,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "def theoretical_minimum_snark1_time(validator_count, snark1_threshold, signature_size, sig_agg_rate, max_bitrate):\n",
    "    \"\"\"\n",
    "    Calculate the theoretical minimum SNARK1 aggregation time based on parameters.\n",
    "    \n",
    "    Args:\n",
    "        validator_count: Total number of validators\n",
    "        snark1_threshold: Threshold for SNARK1 generation (0-1)\n",
    "        signature_size: Size of each signature in bytes\n",
    "        sig_agg_rate: Rate of signature aggregation per second\n",
    "        max_bitrate: Maximum bandwidth in bytes per second (None for unlimited)\n",
    "        \n",
    "    Returns:\n",
    "        Theoretical minimum SNARK1 aggregation time in milliseconds\n",
    "    \"\"\"\n",
    "    if max_bitrate is None:\n",
    "        max_bitrate = float('inf')  # No limit\n",
    "    \n",
    "    # Calculate total data size to aggregate\n",
    "    total_data_size = validator_count * signature_size * snark1_threshold  # in bytes\n",
    "\n",
    "    # Calculate time to aggregate at the given rate\n",
    "    agg_time_sec = validator_count * snark1_threshold  / sig_agg_rate  # in seconds\n",
    "\n",
    "    # Calculate time based on bandwidth limit\n",
    "    bandwidth_time_sec = total_data_size / max_bitrate  # in seconds\n",
    "    \n",
    "    min_time_sec = agg_time_sec + bandwidth_time_sec\n",
    "    \n",
    "    return min_time_sec * 1000  # Convert to milliseconds\n",
    "\n",
    "\n",
    "def run_parameter_analysis(parameter_name, parameter_values, topologies=[\"gossip\", \"grid\"], \n",
    "                          display_name=None, display_unit=\"\", parallel=True, max_workers=None, \n",
    "                          **base_config):\n",
    "    \"\"\"\n",
    "    Generic function to analyze the effect of changing a parameter on SNARK1 aggregation time.\n",
    "    \n",
    "    Args:\n",
    "        parameter_name: Name of the parameter to vary (e.g., 'signature_size', 'mesh_n')\n",
    "        parameter_values: List of values to test for the parameter\n",
    "        topologies: List of network topologies to test\n",
    "        display_name: Human-readable name for the parameter (defaults to parameter_name)\n",
    "        display_unit: Unit to display after the parameter value (e.g., \"KB\", \"Mbps\")\n",
    "        parallel: Whether to run simulations in parallel (default: True)\n",
    "        max_workers: Maximum number of parallel workers (default: min(8, cpu_count()))\n",
    "        **base_config: Base configuration parameters and run kwargs\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with results, with parameter order preserved\n",
    "    \"\"\"\n",
    "    \n",
    "    if display_name is None:\n",
    "        display_name = parameter_name.replace('_', ' ').title()\n",
    "    \n",
    "    # Separate run kwargs from config overrides\n",
    "    run_kwargs_keys = {'mpi', 'c', 'b', 'g', 'gv', 'la', 'ga', 'shuffle', 't', 'local_aggregation_only'}\n",
    "    run_kwargs = {k: v for k, v in base_config.items() if k in run_kwargs_keys}\n",
    "    config_overrides = {k: v for k, v in base_config.items() if k not in run_kwargs_keys}\n",
    "    \n",
    "    # Determine the number of workers (use ThreadPoolExecutor which works better in Jupyter)\n",
    "    if max_workers is None:\n",
    "        max_workers = min(8, len(parameter_values) * len(topologies))  # Conservative default\n",
    "    \n",
    "    print(f\"Testing {display_name}: {parameter_values}\")\n",
    "    print(f\"Topologies: {topologies}\")\n",
    "    \n",
    "    if parallel:\n",
    "        print(f\"Running simulations in parallel with {max_workers} workers (ThreadPoolExecutor)...\\n\")\n",
    "    else:\n",
    "        print(\"Running simulations sequentially...\\n\")\n",
    "    \n",
    "    # Prepare all simulation parameters\n",
    "    simulation_params = []\n",
    "    \n",
    "    # Check if idontwant flag is set in config_overrides\n",
    "    idontwant_flag = config_overrides.get('idontwant', None)\n",
    "    \n",
    "    for topology in topologies:\n",
    "        for param_value in parameter_values:\n",
    "            param_display = f\"{param_value} {display_unit}\".strip() if param_value is not None else \"Default/Unlimited\"\n",
    "            \n",
    "            # Handle idontwant flag specially for gossip topology\n",
    "            if topology == \"gossip\" and idontwant_flag is True:\n",
    "                # Run gossip with both idontwant=True and idontwant=False\n",
    "                for idontwant_value in [True, False]:\n",
    "                    # Create separate config overrides for each idontwant value\n",
    "                    gossip_config = config_overrides.copy()\n",
    "                    gossip_config['idontwant'] = idontwant_value\n",
    "                    \n",
    "                    # Create display name that includes idontwant status\n",
    "                    idontwant_suffix = \" (idontwant=True)\" if idontwant_value else \" (idontwant=False)\"\n",
    "                    gossip_param_display = param_display + idontwant_suffix\n",
    "                    \n",
    "                    simulation_params.append((\n",
    "                        topology, param_value, parameter_name, gossip_param_display,\n",
    "                        gossip_config, run_kwargs, display_name, display_unit\n",
    "                    ))\n",
    "            # For grid topology, execute in two modes for signature_half_direct (0 and 4) unless we're varying it directly\n",
    "            elif topology == \"grid\" and parameter_name != 'signature_half_direct':\n",
    "                for sig_hd in [0, 4]:\n",
    "                    grid_config = config_overrides.copy()\n",
    "                    grid_config['signature_half_direct'] = sig_hd\n",
    "                    simulation_params.append((\n",
    "                        topology, param_value, parameter_name, param_display,\n",
    "                        grid_config, run_kwargs, display_name, display_unit\n",
    "                    ))\n",
    "            else:\n",
    "                # For grid (when parameter_name is signature_half_direct) or other topologies, run once with original config\n",
    "                simulation_params.append((\n",
    "                    topology, param_value, parameter_name, param_display,\n",
    "                    config_overrides, run_kwargs, display_name, display_unit\n",
    "                ))\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    if parallel and len(simulation_params) > 1:\n",
    "        # Run simulations in parallel using ThreadPoolExecutor\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            # Submit all tasks\n",
    "            future_to_params = {}\n",
    "            for params in simulation_params:\n",
    "                topology, param_value, parameter_name, param_display, config_overrides, run_kwargs, display_name, display_unit = params\n",
    "                future = executor.submit(_run_single_simulation_thread, \n",
    "                                       topology, param_value, parameter_name, param_display,\n",
    "                                       config_overrides, run_kwargs, display_name, display_unit)\n",
    "                future_to_params[future] = params\n",
    "            \n",
    "            # Process completed tasks\n",
    "            total_sims = len(simulation_params)\n",
    "            completed = 0\n",
    "            \n",
    "            for future in as_completed(future_to_params):\n",
    "                completed += 1\n",
    "                result = future.result()\n",
    "                \n",
    "                if result['success']:\n",
    "                    results.append(result)\n",
    "                    label = result.get('topology_display') or beamsim.topology_name.get(result['topology'], result['topology'])\n",
    "                    seeds_info = result.get('num_seeds', 1)\n",
    "                    print(f\"  [{completed}/{total_sims}] {label} - {result['parameter_display']}: \"\n",
    "                          f\"{result['snark1_completion_time']:.1f} ms (avg over {seeds_info} seeds)\")\n",
    "                else:\n",
    "                    print(f\"  [{completed}/{total_sims}] ERROR - {result['topology']} - {result['parameter_display']}: \"\n",
    "                          f\"{result['error']}\")\n",
    "    else:\n",
    "        # Run simulations sequentially (original behavior)\n",
    "        for i, params in enumerate(simulation_params):\n",
    "            topology, param_value, parameter_name, param_display, config_overrides, run_kwargs, display_name, display_unit = params\n",
    "            display_topology = \"gossipsub\" if topology == \"gossip\" else beamsim.topology_name.get(topology, topology)\n",
    "            print(f\"  [{i+1}/{len(simulation_params)}] Testing {display_topology} - {param_display}\")\n",
    "            \n",
    "            result = _run_single_simulation_thread(\n",
    "                topology, param_value, parameter_name, param_display,\n",
    "                config_overrides, run_kwargs, display_name, display_unit\n",
    "            )\n",
    "            \n",
    "            if result['success']:\n",
    "                results.append(result)\n",
    "                seeds_info = result.get('num_seeds', 1)\n",
    "                print(f\"    → {result['snark1_completion_time']:.1f} ms (avg over {seeds_info} seeds)\")                \n",
    "            else:\n",
    "                    print(f\"    → ERROR: {result['error']}\")\n",
    "    \n",
    "    # Convert to DataFrame and preserve parameter order\n",
    "    df = pd.DataFrame(results)\n",
    "    if not df.empty:\n",
    "        # Add an order column to preserve the original parameter order\n",
    "        param_to_order = {param: i for i, param in enumerate(parameter_values)}\n",
    "        df['parameter_order'] = df['parameter_value'].map(param_to_order)\n",
    "        # Sort by topology and parameter order to ensure consistent ordering\n",
    "        df = df.sort_values(['topology', 'parameter_order']).reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_parameter_analysis(results_df, parameter_name, display_name=None, display_unit=\"\", \n",
    "                          title_suffix=\"\", figure_size=(14, 12), include_theoretical=True,\n",
    "                          **base_config):\n",
    "    \"\"\"\n",
    "    Plot the results of a parameter analysis.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame from run_parameter_analysis\n",
    "        parameter_name: Name of the parameter that was varied\n",
    "        display_name: Human-readable name for the parameter\n",
    "        display_unit: Unit for the parameter\n",
    "        title_suffix: Additional text for the plot title\n",
    "        figure_size: Size of the plot figure\n",
    "        include_theoretical: Whether to include theoretical minimum line\n",
    "        **base_config: Base configuration parameters for theoretical calculations\n",
    "    \"\"\"\n",
    "    \n",
    "    if display_name is None:\n",
    "        display_name = parameter_name.replace('_', ' ').title()\n",
    "    \n",
    "    # Create subplots - one for SNARK1 time, one for signature duplicates\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=figure_size)\n",
    "    \n",
    "    # Plot lines for each topology display (handles idontwant variations)\n",
    "    topology_displays = results_df['topology_display'].unique()\n",
    "    colors = sns.color_palette(\"husl\", len(topology_displays))\n",
    "    \n",
    "    # Get parameter order from the dataframe (preserves original input order)\n",
    "    # Remove idontwant suffixes for parameter ordering\n",
    "    results_df_clean = results_df.copy()\n",
    "    results_df_clean['parameter_display_clean'] = results_df_clean['parameter_display'].str.replace(r' \\(idontwant=(?:True|False)\\)', '', regex=True)\n",
    "    \n",
    "    if 'parameter_order' in results_df_clean.columns:\n",
    "        # Use the preserved order\n",
    "        ordered_params = results_df_clean.sort_values('parameter_order')['parameter_display_clean'].unique()\n",
    "    else:\n",
    "        # Fallback to original behavior\n",
    "        ordered_params = results_df_clean['parameter_display_clean'].unique()\n",
    "    \n",
    "    # Plot 1: SNARK1 Aggregation Time\n",
    "    plt.sca(ax1)  # Set current axis\n",
    "    for i, topology_display in enumerate(topology_displays):\n",
    "        topo_data = results_df[results_df['topology_display'] == topology_display].copy()\n",
    "        \n",
    "        # Sort by parameter order to maintain input sequence\n",
    "        if 'parameter_order' in topo_data.columns:\n",
    "            topo_data = topo_data.sort_values('parameter_order')\n",
    "        else:\n",
    "            # Fallback: try to sort by parameter value if numeric\n",
    "            try:\n",
    "                topo_data = topo_data.sort_values('parameter_value')\n",
    "            except:\n",
    "                pass  # Keep original order if sorting fails\n",
    "        \n",
    "        x_values = list(range(len(topo_data)))\n",
    "        y_values = topo_data['snark1_completion_time'].tolist()\n",
    "        \n",
    "        ax1.plot(\n",
    "            x_values,\n",
    "            y_values,\n",
    "            marker='o',\n",
    "            linewidth=3,\n",
    "            markersize=8,\n",
    "            color=colors[i],\n",
    "            label=topology_display,\n",
    "            alpha=0.8\n",
    "        )\n",
    "    \n",
    "    # Add theoretical minimum line if requested\n",
    "    if include_theoretical and len(results_df) > 0:\n",
    "        # Get default parameters for theoretical calculation\n",
    "        # Use the global DEFAULT_CONFIG as the base for theoretical calculations\n",
    "        theoretical_params = {**DEFAULT_CONFIG, **base_config}\n",
    "        \n",
    "        # Convert max_bitrate to bytes per second if it's a string\n",
    "        max_bitrate = theoretical_params['max_bitrate']\n",
    "        if isinstance(max_bitrate, str) and max_bitrate.endswith('Mbps'):\n",
    "            max_bitrate_mbps = float(max_bitrate[:-4])\n",
    "            max_bitrate_bps = max_bitrate_mbps * 1024 * 1024 / 8  # Convert Mbps to bytes/sec\n",
    "        elif max_bitrate is None:\n",
    "            max_bitrate_bps = None\n",
    "        else:\n",
    "            max_bitrate_bps = max_bitrate\n",
    "        \n",
    "        # Calculate total validator count (group_count * group_validator_count)\n",
    "        total_validator_count = theoretical_params['group_validator_count']\n",
    "        \n",
    "        # Calculate theoretical minimum times for each parameter value\n",
    "        theoretical_times = []\n",
    "        sample_data = results_df.sort_values('parameter_order' if 'parameter_order' in results_df.columns else 'parameter_value')\n",
    "        unique_param_values = sample_data['parameter_value'].unique()\n",
    "        \n",
    "        for param_value in unique_param_values:\n",
    "            # Update the parameter being analyzed\n",
    "            current_params = theoretical_params.copy()\n",
    "            current_params[parameter_name] = param_value\n",
    "            \n",
    "            # Handle special cases for parameter-specific calculations\n",
    "            if parameter_name == 'max_bitrate':\n",
    "                if isinstance(param_value, str) and param_value.endswith('Mbps'):\n",
    "                    max_bitrate_mbps = float(param_value[:-4])\n",
    "                    current_max_bitrate = max_bitrate_mbps * 1024 * 1024 / 8\n",
    "                elif param_value is None:\n",
    "                    current_max_bitrate = None\n",
    "                else:\n",
    "                    current_max_bitrate = param_value\n",
    "            else:\n",
    "                current_max_bitrate = max_bitrate_bps\n",
    "            \n",
    "            # Recalculate total validator count if group parameters changed\n",
    "            if parameter_name in ['group_count', 'group_validator_count']:\n",
    "                current_total_validators = current_params['group_validator_count']\n",
    "            else:\n",
    "                current_total_validators = total_validator_count\n",
    "            \n",
    "            theoretical_time = theoretical_minimum_snark1_time(\n",
    "                validator_count=current_total_validators,\n",
    "                snark1_threshold=current_params['snark1_threshold'],\n",
    "                signature_size=current_params['signature_size'],\n",
    "                sig_agg_rate=current_params['aggregation_rate_per_sec'],\n",
    "                max_bitrate=current_max_bitrate\n",
    "            )\n",
    "            theoretical_times.append(theoretical_time)\n",
    "        \n",
    "        # Plot theoretical minimum line\n",
    "        x_values = list(range(len(theoretical_times)))\n",
    "        ax1.plot(\n",
    "            x_values,\n",
    "            theoretical_times,\n",
    "            linestyle='--',\n",
    "            linewidth=2,\n",
    "            color='red',\n",
    "            label='Theoretical Minimum',\n",
    "            alpha=0.8\n",
    "        )\n",
    "    \n",
    "    # Set axis labels and title for first plot\n",
    "    ax1.set_xlabel(f'{display_name} {display_unit}'.strip(), fontweight='bold', fontsize=12)\n",
    "    ax1.set_ylabel('SNARK1 Aggregation Time (ms)', fontweight='bold', fontsize=12)\n",
    "    \n",
    "    title = f'Effect of {display_name} on SNARK1 Aggregation Time'\n",
    "    if title_suffix:\n",
    "        title += f'\\n{title_suffix}'\n",
    "    title += '\\n(Local Aggregation Only Mode – averages over 5 seeds)'\n",
    "    ax1.set_title(title, fontweight='bold', fontsize=14)\n",
    "    \n",
    "    # Set x-axis tick labels using preserved parameter order\n",
    "    ax1.set_xticks(range(len(ordered_params)))\n",
    "    ax1.set_xticklabels(ordered_params, rotation=45)\n",
    "    \n",
    "    ax1.legend(frameon=True, fancybox=True, shadow=True, fontsize=11)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add performance annotations for first plot\n",
    "    if len(results_df) > 0:\n",
    "        min_time = results_df['snark1_completion_time'].min()\n",
    "        max_time = results_df['snark1_completion_time'].max()\n",
    "        time_diff = max_time - min_time\n",
    "        improvement = (time_diff / max_time) * 100 if max_time else 0\n",
    "        \n",
    "        ax1.text(0.02, 0.98, \n",
    "                f'Max time difference: {time_diff:.1f}ms\\n'\n",
    "                f'Performance improvement: {improvement:.1f}%',\n",
    "                transform=ax1.transAxes,\n",
    "                verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8),\n",
    "                fontsize=10)\n",
    "    \n",
    "    # Plot 2: Average Signature Duplicates per Validator\n",
    "    plt.sca(ax2)  # Set current axis\n",
    "    if 'avg_signature_duplicates' in results_df.columns:\n",
    "        for i, topology_display in enumerate(topology_displays):\n",
    "            topo_data = results_df[results_df['topology_display'] == topology_display].copy()\n",
    "            \n",
    "            # Sort by parameter order to maintain input sequence\n",
    "            if 'parameter_order' in topo_data.columns:\n",
    "                topo_data = topo_data.sort_values('parameter_order')\n",
    "            else:\n",
    "                try:\n",
    "                    topo_data = topo_data.sort_values('parameter_value')\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            x_values = list(range(len(topo_data)))\n",
    "            y_values = topo_data['avg_signature_duplicates'].tolist()\n",
    "            \n",
    "            ax2.plot(\n",
    "                x_values,\n",
    "                y_values,\n",
    "                marker='s',  # Square markers to differentiate from time plot\n",
    "                linewidth=3,\n",
    "                markersize=8,\n",
    "                color=colors[i],\n",
    "                label=topology_display,\n",
    "                alpha=0.8\n",
    "            )\n",
    "        \n",
    "        # Set axis labels and title for second plot\n",
    "        ax2.set_xlabel(f'{display_name} {display_unit}'.strip(), fontweight='bold', fontsize=12)\n",
    "        ax2.set_ylabel('Average Signature Duplicates per Validator', fontweight='bold', fontsize=12)\n",
    "        ax2.set_title(f'Effect of {display_name} on Average Signature Duplicates per Validator', fontweight='bold', fontsize=14)\n",
    "        \n",
    "        # Set x-axis tick labels\n",
    "        ax2.set_xticks(range(len(ordered_params)))\n",
    "        ax2.set_xticklabels(ordered_params, rotation=45)\n",
    "        \n",
    "        ax2.legend(frameon=True, fancybox=True, shadow=True, fontsize=11)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add duplicate message statistics\n",
    "        if len(results_df) > 0:\n",
    "            min_dups = results_df['avg_signature_duplicates'].min()\n",
    "            max_dups = results_df['avg_signature_duplicates'].max()\n",
    "            avg_dups = results_df['avg_signature_duplicates'].mean()\n",
    "            \n",
    "            ax2.text(0.02, 0.98, \n",
    "                    f'Min avg duplicates: {min_dups:.3f}\\n'\n",
    "                    f'Max avg duplicates: {max_dups:.3f}\\n'\n",
    "                    f'Overall avg: {avg_dups:.3f}',\n",
    "                    transform=ax2.transAxes,\n",
    "                    verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.8),\n",
    "                    fontsize=10)\n",
    "    else:\n",
    "        # If no duplicate data is available, show a message\n",
    "        ax2.text(0.5, 0.5, 'Average signature duplicate data not available',\n",
    "                transform=ax2.transAxes, ha='center', va='center',\n",
    "                fontsize=14, style='italic')\n",
    "        ax2.set_xlim(0, 1)\n",
    "        ax2.set_ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"{display_name.upper()} EFFECT SUMMARY (averages over 5 seeds)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Print theoretical minimum information if included\n",
    "    if include_theoretical and len(results_df) > 0:\n",
    "        print(f\"\\nTheoretical Minimum:\")\n",
    "        print(f\"  SNARK1 time range: {min(theoretical_times):.1f} - {max(theoretical_times):.1f} ms\")\n",
    "        print(f\"  Time difference: {max(theoretical_times) - min(theoretical_times):.1f} ms\")\n",
    "        \n",
    "        # Show theoretical minimum for each parameter value\n",
    "        sample_data = results_df_clean.sort_values('parameter_order' if 'parameter_order' in results_df_clean.columns else 'parameter_value')\n",
    "        unique_param_displays = sample_data['parameter_display_clean'].unique()\n",
    "        for i, param_display in enumerate(unique_param_displays):\n",
    "            print(f\"    {param_display:>12}: {theoretical_times[i]:.1f} ms\")\n",
    "    \n",
    "    for topology_display in topology_displays:\n",
    "        topo_data = results_df[results_df['topology_display'] == topology_display]\n",
    "        if len(topo_data) > 0:\n",
    "            print(f\"\\n{topology_display}:\")\n",
    "            print(f\"  SNARK1 time range: {topo_data['snark1_completion_time'].min():.1f} - {topo_data['snark1_completion_time'].max():.1f} ms\")\n",
    "            print(f\"  Time difference: {topo_data['snark1_completion_time'].max() - topo_data['snark1_completion_time'].min():.1f} ms\")\n",
    "            \n",
    "            # Add signature duplicate statistics if available\n",
    "            if 'avg_signature_duplicates' in topo_data.columns:\n",
    "                print(f\"  Avg duplicates per validator range: {topo_data['avg_signature_duplicates'].min():.3f} - {topo_data['avg_signature_duplicates'].max():.3f}\")\n",
    "                print(f\"  Overall avg duplicates per validator: {topo_data['avg_signature_duplicates'].mean():.3f}\")\n",
    "                if 'signature_duplicates' in topo_data.columns:\n",
    "                    print(f\"  Total signature duplicates range: {topo_data['signature_duplicates'].min():.0f} - {topo_data['signature_duplicates'].max():.0f} messages\")\n",
    "            \n",
    "            # Show performance for each parameter value\n",
    "            for _, row in topo_data.iterrows():\n",
    "                dup_info = \"\"\n",
    "                if 'avg_signature_duplicates' in row:\n",
    "                    dup_info = f\" (avg dups: {row['avg_signature_duplicates']:.3f})\"\n",
    "                # Clean up parameter display for output (remove idontwant suffix)\n",
    "                clean_param_display = row['parameter_display'].replace(' (idontwant=True)', '').replace(' (idontwant=False)', '')\n",
    "                print(f\"    {clean_param_display:>12}: {row['snark1_completion_time']:.1f} ms{dup_info}\")\n",
    "\n",
    "\n",
    "def analyze_parameter_effect(parameter_name, parameter_values, topologies=[\"gossip\", \"grid\"], \n",
    "                           display_name=None, display_unit=\"\", title_suffix=\"\", \n",
    "                           parallel=True, max_workers=None, **base_config):\n",
    "    \"\"\"\n",
    "    Complete analysis workflow: run simulations and plot results.\n",
    "    \n",
    "    Args:\n",
    "        parameter_name: Name of the parameter to vary\n",
    "        parameter_values: List of values to test\n",
    "        topologies: List of topologies to test\n",
    "        display_name: Human-readable parameter name\n",
    "        display_unit: Unit for the parameter\n",
    "        title_suffix: Additional text for plot title\n",
    "        parallel: Whether to run simulations in parallel (default: True)\n",
    "        max_workers: Maximum number of parallel workers (default: cpu_count())\n",
    "        **base_config: Base configuration and run parameters\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Run the analysis\n",
    "    results_df = run_parameter_analysis(\n",
    "        parameter_name, parameter_values, topologies, \n",
    "        display_name, display_unit, parallel=parallel, \n",
    "        max_workers=max_workers, **base_config\n",
    "    )\n",
    "    \n",
    "    # Plot the results\n",
    "    plot_parameter_analysis(\n",
    "        results_df, parameter_name, display_name, \n",
    "        display_unit, title_suffix, **base_config\n",
    "    )\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee17544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_bandwidth_effect(bandwidth_limits, signature_size=3072, topologies=[\"gossip\", \"grid\"], \n",
    "                            parallel=True, max_workers=None, **base_config):\n",
    "    \"\"\"\n",
    "    Analyze how max incoming bandwidth affects SNARK1 aggregation time using the refactored framework.\n",
    "    Each configuration is run across 5 seeds and averaged (handled by core functions).\n",
    "    \n",
    "    Args:\n",
    "        bandwidth_limits: List of bandwidth limits to test (in Mbps, None for unlimited)\n",
    "        signature_size: Fixed signature size to use (in bytes)\n",
    "        topologies: List of network topologies to test\n",
    "        parallel: Whether to run simulations in parallel (default: True)\n",
    "        max_workers: Maximum number of parallel workers (default: cpu_count())\n",
    "        **base_config: Base configuration parameters\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with results\n",
    "    \"\"\"\n",
    "    # Convert bandwidth values to the format expected by the YAML config\n",
    "    bandwidth_values = []\n",
    "    for bw in bandwidth_limits:\n",
    "        if bw is None:\n",
    "            bandwidth_values.append(None)\n",
    "        else:\n",
    "            bandwidth_values.append(f\"{bw}Mbps\")\n",
    "    \n",
    "    return analyze_parameter_effect(\n",
    "        parameter_name='max_bitrate',\n",
    "        parameter_values=bandwidth_values,\n",
    "        topologies=topologies,\n",
    "        display_name='Max Incoming Bandwidth',\n",
    "        display_unit='',\n",
    "        title_suffix=f'Signature Size: {signature_size/1024:.1f} KB',\n",
    "        parallel=parallel,\n",
    "        max_workers=max_workers,\n",
    "        signature_size=signature_size,  # Fixed signature size\n",
    "        **base_config\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9911dec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_signature_size_effect(signature_sizes, topologies=[\"gossip\", \"grid\"], \n",
    "                                 parallel=True, max_workers=None, **base_config):\n",
    "    \"\"\"\n",
    "    Analyze how signature size affects SNARK1 aggregation time and signature duplicates.\n",
    "    Each configuration is run across 5 different seeds and averaged (handled by core functions).\n",
    "    \n",
    "    Args:\n",
    "        signature_sizes: List of signature sizes to test (in bytes)\n",
    "        topologies: List of network topologies to test\n",
    "        parallel: Whether to run simulations in parallel (default: True)\n",
    "        max_workers: Maximum number of parallel workers (default: cpu_count())\n",
    "        **base_config: Base configuration parameters\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with results\n",
    "    \"\"\"\n",
    "    return analyze_parameter_effect(\n",
    "        parameter_name='signature_size',\n",
    "        parameter_values=signature_sizes,\n",
    "        topologies=topologies,\n",
    "        display_name='Signature Size',\n",
    "        display_unit='bytes',\n",
    "        title_suffix='Network Performance and Efficiency Analysis',\n",
    "        parallel=parallel,\n",
    "        max_workers=max_workers,\n",
    "        **base_config,\n",
    "    )\n",
    "\n",
    "\n",
    "def analyze_mesh_n_effect(mesh_n_values, topologies=[\"gossip\"], parallel=True, max_workers=None, **base_config):\n",
    "    \"\"\"\n",
    "    Analyze how mesh_n (gossip mesh size) affects SNARK1 aggregation time and signature duplicates.\n",
    "    Each configuration is run across 5 different seeds and averaged (handled by core functions).\n",
    "    \n",
    "    Args:\n",
    "        mesh_n_values: List of mesh_n values to test\n",
    "        topologies: List of network topologies to test (typically just \"gossip\")\n",
    "        parallel: Whether to run simulations in parallel (default: True)\n",
    "        max_workers: Maximum number of parallel workers (default: cpu_count())\n",
    "        **base_config: Base configuration parameters\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with results\n",
    "    \"\"\"\n",
    "    return analyze_parameter_effect(\n",
    "        parameter_name='mesh_n',\n",
    "        parameter_values=mesh_n_values,\n",
    "        topologies=topologies,\n",
    "        display_name='Mesh N',\n",
    "        display_unit='peers',\n",
    "        title_suffix='Gossip Network Configuration Analysis',\n",
    "        parallel=parallel,\n",
    "        max_workers=max_workers,\n",
    "        **base_config,\n",
    "    )\n",
    "\n",
    "\n",
    "def analyze_group_validator_count_effect(validator_counts, topologies=[\"gossip\", \"grid\"], \n",
    "                                       parallel=True, max_workers=None, **base_config):\n",
    "    \"\"\"\n",
    "    Analyze how group_validator_count affects SNARK1 aggregation time and signature duplicates.\n",
    "    Each configuration is run across 5 different seeds and averaged (handled by core functions).\n",
    "    \n",
    "    Args:\n",
    "        validator_counts: List of validator counts per group to test\n",
    "        topologies: List of network topologies to test\n",
    "        parallel: Whether to run simulations in parallel (default: True)\n",
    "        max_workers: Maximum number of parallel workers (default: cpu_count())\n",
    "        **base_config: Base configuration parameters\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with results\n",
    "    \"\"\"\n",
    "    return analyze_parameter_effect(\n",
    "        parameter_name='group_validator_count',\n",
    "        parameter_values=validator_counts,\n",
    "        topologies=topologies,\n",
    "        display_name='Group Validator Count',\n",
    "        display_unit='validators',\n",
    "        title_suffix='Network Scale Analysis',\n",
    "        parallel=parallel,\n",
    "        max_workers=max_workers,\n",
    "        **base_config,\n",
    "    )\n",
    "\n",
    "\n",
    "def analyze_local_aggregator_count_effect(aggregator_counts, topologies=[\"gossip\", \"grid\"], \n",
    "                                        parallel=True, max_workers=None, **base_config):\n",
    "    \"\"\"\n",
    "    Analyze how group_local_aggregator_count affects SNARK1 aggregation time and signature duplicates.\n",
    "    Each configuration is run across 5 different seeds and averaged (handled by core functions).\n",
    "    \n",
    "    Args:\n",
    "        aggregator_counts: List of local aggregator counts per group to test\n",
    "        topologies: List of network topologies to test\n",
    "        parallel: Whether to run simulations in parallel (default: True)\n",
    "        max_workers: Maximum number of parallel workers (default: cpu_count())\n",
    "        **base_config: Base configuration parameters\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with results\n",
    "    \"\"\"\n",
    "    return analyze_parameter_effect(\n",
    "        parameter_name='group_local_aggregator_count',\n",
    "        parameter_values=aggregator_counts,\n",
    "        topologies=topologies,\n",
    "        display_name='Local Aggregator Count',\n",
    "        display_unit='aggregators',\n",
    "        title_suffix='Aggregation Capacity Analysis',\n",
    "        parallel=parallel,\n",
    "        max_workers=max_workers,\n",
    "        **base_config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308510c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "topologies = [\"gossip\", \"grid\"]\n",
    "\n",
    "# Signature Size Analysis - Using the refactored approach\n",
    "# This demonstrates how the new framework simplifies the analysis process\n",
    "\n",
    "# Test different signature sizes to analyze their effect on SNARK1 aggregation time\n",
    "signature_sizes = [\n",
    "    96,      # 96 bytes - very small signature (BLS)\n",
    "    1024,    # 1 KB - small signature\n",
    "    2048,    # 2 KB - medium-small signature  \n",
    "    3072,    # 3 KB - default signature size\n",
    "    4096,    # 4 KB - medium signature\n",
    "]\n",
    "\n",
    "# Base configuration parameters\n",
    "base_config = {\n",
    "    'mpi': False,  # Use MPI for faster simulations\n",
    "    # Add any other base parameters you want to override\n",
    "}\n",
    "\n",
    "# Test on both gossip and grid topologies\n",
    "topologies = [\"gossip\", \"grid\"]\n",
    "\n",
    "print(\"Analyzing the effect of signature size on SNARK1 aggregation time...\")\n",
    "print(\"Using the refactored analysis framework for cleaner code.\\n\")\n",
    "\n",
    "# Run the signature size effect analysis using the new framework\n",
    "results_df = analyze_signature_size_effect(signature_sizes, topologies, max_workers=5, idontwant=True, **base_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eb93d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze bandwidth limits\n",
    "bandwidth_limits = [5, 25, 50, 100, 200]\n",
    "print(\"\\nAnalyzing the effect of max incoming bandwidth on SNARK1 aggregation time...\")\n",
    "bandwidth_results = analyze_bandwidth_effect(\n",
    "    bandwidth_limits, signature_size=3072, topologies=topologies,\n",
    "    max_workers=5, idontwant=True, **base_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daf94de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example analyses for new parameters using the refactored framework\n",
    "# These demonstrate how easy it is to analyze different parameters\n",
    "\n",
    "# Example 1: Analyze mesh_n effect (gossip network mesh size)\n",
    "print(\"=\"*60)\n",
    "print(\"EXAMPLE 1: Mesh N Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "mesh_n_values = [4, 6, 8, 10, 12]  # Different mesh sizes\n",
    "base_config = {'mpi': False, 'signature_size': 3072}\n",
    "\n",
    "mesh_n_results = analyze_mesh_n_effect(mesh_n_values, topologies=[\"gossip\"], max_workers=5, idontwant=True, **base_config)\n",
    "\n",
    "\n",
    "# Example 2: Analyze non_mesh_n effect (gossip non-mesh connections)\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"EXAMPLE 2: Non-Mesh N Analysis\")\n",
    "# print(\"=\"*60)\n",
    "\n",
    "# non_mesh_n_values = [2, 4, 6, 8, 10]  # Different non-mesh connection counts\n",
    "# base_config = {'mpi': False, 'signature_size': 3072}\n",
    "\n",
    "# non_mesh_n_results = analyze_non_mesh_n_effect(non_mesh_n_values, topologies=[\"gossip\"], max_workers=5, **base_config)\n",
    "\n",
    "\n",
    "# Example 3: Analyze group_validator_count effect (network scale)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXAMPLE 3: Group Validator Count Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "validator_counts = [128, 256, 512, 768, 1024]  # Different validator counts per group\n",
    "base_config = {'mpi': False, 'signature_size': 3072}\n",
    "\n",
    "validator_count_results = analyze_group_validator_count_effect(validator_counts, topologies=[\"gossip\", \"grid\"], idontwant=True, **base_config)\n",
    "\n",
    "\n",
    "# Example 4: Analyze local aggregator count effect\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXAMPLE 4: Local Aggregator Count Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "aggregator_counts = [10, 102, 256, 512]  # Different local aggregator counts\n",
    "base_config = {'mpi': False, 'signature_size': 3072}\n",
    "\n",
    "aggregator_count_results = analyze_local_aggregator_count_effect(aggregator_counts, topologies=[\"gossip\", \"grid\"], max_workers=5, idontwant=True, **base_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a428e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for optimal (mesh_n, signature_half_direct) on gossipsub\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def _run_gossipsub_single(mesh_n, signature_half_direct, config_overrides, run_kwargs):\n",
    "    try:\n",
    "        # Run the same combo across 5 seeds and average\n",
    "        base_seed = config_overrides.get('random_seed', DEFAULT_CONFIG.get('random_seed', 42))\n",
    "        seed_values = [base_seed + i for i in range(5)]\n",
    "\n",
    "        times_ms = []\n",
    "        dup_counts = []\n",
    "        dup_avgs = []\n",
    "        validator_count = None\n",
    "        snark1_threshold = None\n",
    "\n",
    "        for seed in seed_values:\n",
    "            current_config = {**config_overrides, 'mesh_n': mesh_n, 'signature_half_direct': signature_half_direct, 'random_seed': seed}\n",
    "            modified_yaml = generate_yaml_config(topology='gossip', **current_config)\n",
    "            current_run_kwargs = {**run_kwargs, 'c': modified_yaml}\n",
    "            items = beamsim.run(**current_run_kwargs, t='gossip', local_aggregation_only=True)\n",
    "\n",
    "            snark1_sent = beamsim.get_snark1_sent(items)\n",
    "            if snark1_sent and len(snark1_sent[0]) > 0:\n",
    "                snark1_completion_time = snark1_sent[0][-1] if snark1_sent[0] else 0\n",
    "                times_ms.append(snark1_completion_time)\n",
    "                _, _, validator_count, snark1_threshold, _ = beamsim.filter_report(items, 'info')[0]\n",
    "                try:\n",
    "                    signature_duplicates, avg_duplicates = beamsim.get_signature_duplicates(items)\n",
    "                except Exception:\n",
    "                    signature_duplicates, avg_duplicates = 0, 0.0\n",
    "                dup_counts.append(signature_duplicates)\n",
    "                dup_avgs.append(avg_duplicates)\n",
    "            # else skip this seed\n",
    "\n",
    "        if times_ms:\n",
    "            return {\n",
    "                'success': True,\n",
    "                'mesh_n': mesh_n,\n",
    "                'signature_half_direct': signature_half_direct,\n",
    "                'snark1_completion_time': float(np.mean(times_ms)),\n",
    "                'validator_count': validator_count,\n",
    "                'snark1_threshold': snark1_threshold,\n",
    "                'signature_duplicates': float(np.mean(dup_counts)) if dup_counts else 0.0,\n",
    "                'avg_signature_duplicates': float(np.mean(dup_avgs)) if dup_avgs else 0.0,\n",
    "                'num_seeds': len(times_ms),\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'mesh_n': mesh_n,\n",
    "                'signature_half_direct': signature_half_direct,\n",
    "                'error': 'No SNARK1 data found across seeds',\n",
    "            }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'success': False,\n",
    "            'mesh_n': mesh_n,\n",
    "            'signature_half_direct': signature_half_direct,\n",
    "            'error': str(e),\n",
    "        }\n",
    "\n",
    "\n",
    "def run_gossipsub_grid_search(mesh_values, sig_hd_values, parallel=True, max_workers=None, **base_config):\n",
    "    \"\"\"\n",
    "    Run parameter search on gossipsub for mesh_n and signature_half_direct combinations.\n",
    "    Each combo is executed over 5 seeds and averaged.\n",
    "\n",
    "    Returns a DataFrame with results and prints progress.\n",
    "    \"\"\"\n",
    "    run_kwargs_keys = {'mpi', 'c', 'b', 'g', 'gv', 'la', 'ga', 'shuffle', 't', 'local_aggregation_only'}\n",
    "    run_kwargs = {k: v for k, v in base_config.items() if k in run_kwargs_keys}\n",
    "    config_overrides = {k: v for k, v in base_config.items() if k not in run_kwargs_keys}\n",
    "\n",
    "    combos = [(m, s) for m in mesh_values for s in sig_hd_values]\n",
    "    if max_workers is None:\n",
    "        max_workers = min(8, len(combos))\n",
    "\n",
    "    print(f\"Searching gossipsub over mesh_n={mesh_values} and signature_half_direct={sig_hd_values}\")\n",
    "    print(f\"Parallel: {parallel} (workers={max_workers if parallel else 1})\\n\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    if parallel and len(combos) > 1:\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = {}\n",
    "            for mesh_n, shd in combos:\n",
    "                futures[executor.submit(_run_gossipsub_single, mesh_n, shd, config_overrides, run_kwargs)] = (mesh_n, shd)\n",
    "            total = len(futures)\n",
    "            done = 0\n",
    "            for fut in as_completed(futures):\n",
    "                done += 1\n",
    "                res = fut.result()\n",
    "                if res.get('success'):\n",
    "                    results.append(res)\n",
    "                    print(f\"  [{done}/{total}] gossipsub - mesh_n={res['mesh_n']}, signature_half_direct={res['signature_half_direct']}: {res['snark1_completion_time']:.1f} ms (avg over {res.get('num_seeds', 1)} seeds)\")\n",
    "                else:\n",
    "                    m, s = futures[fut]\n",
    "                    print(f\"  [{done}/{total}] ERROR - mesh_n={m}, signature_half_direct={s}: {res.get('error')}\")\n",
    "    else:\n",
    "        for i, (mesh_n, shd) in enumerate(combos, start=1):\n",
    "            print(f\"  [{i}/{len(combos)}] Testing gossipsub - mesh_n={mesh_n}, signature_half_direct={shd}\")\n",
    "            res = _run_gossipsub_single(mesh_n, shd, config_overrides, run_kwargs)\n",
    "            if res.get('success'):\n",
    "                results.append(res)\n",
    "                print(f\"    → {res['snark1_completion_time']:.1f} ms (avg over {res.get('num_seeds', 1)} seeds)\")\n",
    "            else:\n",
    "                print(f\"    → ERROR: {res.get('error')}\")\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    if df.empty:\n",
    "        print(\"No successful results produced.\")\n",
    "        return df\n",
    "\n",
    "    # Identify best configuration (min time, then min duplicates)\n",
    "    df_sorted = df.sort_values(['snark1_completion_time', 'avg_signature_duplicates', 'mesh_n', 'signature_half_direct']).reset_index(drop=True)\n",
    "    best = df_sorted.iloc[0].to_dict()\n",
    "    print(\"\\nBest configuration (gossipsub, averaged over 5 seeds):\")\n",
    "    print(f\"  mesh_n={best['mesh_n']}, signature_half_direct={best['signature_half_direct']} → {best['snark1_completion_time']:.1f} ms (avg dups {best['avg_signature_duplicates']:.3f})\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_gossipsub_grid_search(results_df, value_col='snark1_completion_time', cmap='viridis'):\n",
    "    \"\"\"\n",
    "    Visualize grid search results as heatmaps for time and duplicates (averages over seeds).\n",
    "    \"\"\"\n",
    "    if results_df.empty:\n",
    "        print(\"No results to plot.\")\n",
    "        return\n",
    "\n",
    "    # Ensure proper ordering\n",
    "    mesh_order = sorted(results_df['mesh_n'].unique())\n",
    "    shd_order = sorted(results_df['signature_half_direct'].unique())\n",
    "\n",
    "    pivot_time = results_df.pivot_table(index='mesh_n', columns='signature_half_direct', values='snark1_completion_time', aggfunc='mean').reindex(index=mesh_order, columns=shd_order)\n",
    "    pivot_dups = results_df.pivot_table(index='mesh_n', columns='signature_half_direct', values='avg_signature_duplicates', aggfunc='mean').reindex(index=mesh_order, columns=shd_order)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    sns.heatmap(pivot_time, annot=True, fmt='.1f', cmap=cmap, ax=ax1)\n",
    "    ax1.set_title('Gossipsub: SNARK1 time (ms) by mesh_n × signature_half_direct (avg over 5 seeds)', fontweight='bold')\n",
    "    ax1.set_xlabel('signature_half_direct')\n",
    "    ax1.set_ylabel('mesh_n')\n",
    "\n",
    "    sns.heatmap(pivot_dups, annot=True, fmt='.3f', cmap='magma', ax=ax2)\n",
    "    ax2.set_title('Gossipsub: Avg signature duplicates by mesh_n × signature_half_direct (avg over 5 seeds)', fontweight='bold')\n",
    "    ax2.set_xlabel('signature_half_direct')\n",
    "    ax2.set_ylabel('mesh_n')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031952e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute grid search on gossipsub for the requested values and visualize\n",
    "mesh_values = [4, 8, 12, 16, 24]\n",
    "sig_hd_values = [0, 1, 4, 8, 16, 24]\n",
    "\n",
    "# Base configuration; inherit defaults and optionally override for speed/reproducibility\n",
    "base_config = {\n",
    "    'mpi': False,\n",
    "    'idontwant': False,          # keep behavior consistent with earlier analyses\n",
    "    'signature_size': DEFAULT_CONFIG['signature_size'],\n",
    "}\n",
    "\n",
    "print(\"Running gossipsub grid search (mesh_n × signature_half_direct)...\")\n",
    "results_grid = run_gossipsub_grid_search(mesh_values, sig_hd_values, parallel=True, max_workers=8, **base_config)\n",
    "\n",
    "# Visualize\n",
    "plot_gossipsub_grid_search(results_grid)\n",
    "\n",
    "# Show top configurations\n",
    "if not results_grid.empty:\n",
    "    topk = results_grid.sort_values(['snark1_completion_time','avg_signature_duplicates']).head(5)\n",
    "    print(\"\\nTop 5 configurations (by SNARK1 time, then duplicates):\")\n",
    "    for _, row in topk.iterrows():\n",
    "        print(f\"  mesh_n={row['mesh_n']:>2}, signature_half_direct={row['signature_half_direct']:>2} → {row['snark1_completion_time']:.1f} ms (avg dups {row['avg_signature_duplicates']:.3f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beamsim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
