{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec545b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import beamsim\n",
    "\n",
    "# Set seaborn style for beautiful plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "plt.rcParams[\"font.size\"] = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2622e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import beamsim\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import current_thread\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Set seaborn style for beautiful plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "plt.rcParams[\"font.size\"] = 11\n",
    "\n",
    "# Default configuration parameters - single source of truth\n",
    "DEFAULT_CONFIG = {\n",
    "    'backend': 'ns3-direct',\n",
    "    'snark1_pull': True,\n",
    "    'snark1_half_direct': True,\n",
    "    'shuffle': False,\n",
    "    'random_seed': 42,\n",
    "    'group_count': 8,\n",
    "    'group_validator_count': 1024,\n",
    "    'group_local_aggregator_count': \"10%\",  # Default to 10% of group validators\n",
    "    'global_aggregator_count': 102,\n",
    "    'mesh_n': 8,\n",
    "    'non_mesh_n': 4,\n",
    "    'signature_time': '20ms',\n",
    "    'signature_size': 3072,\n",
    "    'snark_size': 131072,\n",
    "    'snark1_threshold': 0.9,\n",
    "    'snark2_threshold': 0.66,\n",
    "    'aggregation_rate_per_sec': 1000,\n",
    "    'snark_recursion_aggregation_rate_per_sec': 10,\n",
    "    'pq_signature_verification_time': '30us',\n",
    "    'snark_proof_verification_time': '5ms',\n",
    "    'gml': 'shadow-atlas.bin',\n",
    "    'max_bitrate': '50Mbps'  # Default EIP-7870 bandwidth limit\n",
    "}\n",
    "\n",
    "\n",
    "def generate_yaml_config(topology=\"gossip\", **overrides):\n",
    "    \"\"\"\n",
    "    Generate a YAML configuration with default values and optional overrides.\n",
    "    \n",
    "    Args:\n",
    "        topology: Network topology (\"gossip\", \"grid\", etc.)\n",
    "        **overrides: Dictionary of parameter overrides\n",
    "        \n",
    "    Common override parameters:\n",
    "        - signature_size: Size of signatures in bytes\n",
    "        - max_bitrate: Bandwidth limit (e.g., \"10Mbps\" or None for unlimited)\n",
    "        - mesh_n: Gossip mesh_n parameter\n",
    "        - non_mesh_n: Gossip non_mesh_n parameter\n",
    "        - group_validator_count: Number of validators per group\n",
    "        - group_local_aggregator_count: Number of local aggregators per group\n",
    "        - group_count: Number of groups\n",
    "        - global_aggregator_count: Number of global aggregators\n",
    "        - snark1_threshold: Threshold for SNARK1 generation\n",
    "        - aggregation_rate_per_sec: Rate of signature aggregation\n",
    "        - random_seed: Random seed for reproducibility\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use default configuration and add topology, then apply overrides\n",
    "    defaults = DEFAULT_CONFIG.copy()\n",
    "    defaults['topology'] = topology\n",
    "    \n",
    "    # Apply overrides\n",
    "    config = {**defaults, **overrides}\n",
    "    \n",
    "    # Build the YAML string\n",
    "    yaml_content = f\"\"\"\n",
    "# Simulation Backend Configuration\n",
    "backend: {config['backend']}\n",
    "                                \n",
    "snark1_pull: {str(config['snark1_pull']).lower()}\n",
    "snark1_half_direct: {str(config['snark1_half_direct']).lower()}\n",
    "\n",
    "# Network Topology Configuration\n",
    "topology: {config['topology']}\n",
    "\n",
    "# Whether to shuffle validators from the same group to different routers\n",
    "shuffle: {str(config['shuffle']).lower()}\n",
    "\n",
    "# Seed for reproducible simulation results\n",
    "random_seed: {config['random_seed']}\n",
    "\n",
    "# Role Assignment Configuration\n",
    "roles:\n",
    "  group_count: {config['group_count']}\n",
    "  group_validator_count: {config['group_validator_count']}\n",
    "  group_local_aggregator_count: {config['group_local_aggregator_count']}\n",
    "  global_aggregator_count: {config['global_aggregator_count']}\n",
    "\n",
    "# Gossipsub Network Configuration\n",
    "gossip:\n",
    "  mesh_n: {config['mesh_n']}\n",
    "  non_mesh_n: {config['non_mesh_n']}\n",
    "\n",
    "# Cryptographic Constants\n",
    "consts:\n",
    "  signature_time: {config['signature_time']}\n",
    "  signature_size: {config['signature_size']}\n",
    "  snark_size: {config['snark_size']}\n",
    "  snark1_threshold: {config['snark1_threshold']}\n",
    "  snark2_threshold: {config['snark2_threshold']}\n",
    "  aggregation_rate_per_sec: {config['aggregation_rate_per_sec']}\n",
    "  snark_recursion_aggregation_rate_per_sec: {config['snark_recursion_aggregation_rate_per_sec']}\n",
    "  pq_signature_verification_time: {config['pq_signature_verification_time']}\n",
    "  snark_proof_verification_time: {config['snark_proof_verification_time']}\n",
    "\n",
    "# Network Simulation Parameters\n",
    "network:\n",
    "  gml: \"{config['gml']}\"\n",
    "\"\"\"\n",
    "    \n",
    "    # Add bandwidth constraint if specified\n",
    "    if config['max_bitrate'] is not None:\n",
    "        yaml_content += f\"  max_bitrate: {config['max_bitrate']}\\n\"\n",
    "    \n",
    "    return beamsim.yaml(yaml_content.strip())\n",
    "\n",
    "\n",
    "# Worker function for parallel processing - using ThreadPoolExecutor instead of multiprocessing\n",
    "# to avoid pickle issues in Jupyter notebooks\n",
    "def _run_single_simulation_thread(topology, param_value, parameter_name, param_display, \n",
    "                                 config_overrides, run_kwargs, display_name, display_unit):\n",
    "    \"\"\"\n",
    "    Worker function to run a single simulation in parallel using threading.\n",
    "    \n",
    "    Args:\n",
    "        Individual parameters instead of tuple to avoid pickle issues\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with simulation results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create config with this parameter value\n",
    "        current_config = {**config_overrides, parameter_name: param_value}\n",
    "        modified_yaml = generate_yaml_config(topology=topology, **current_config)\n",
    "        \n",
    "        # Run simulation with modified config\n",
    "        current_run_kwargs = {**run_kwargs, 'c': modified_yaml}\n",
    "        items = beamsim.run(**current_run_kwargs, t=topology, local_aggregation_only=True)\n",
    "        \n",
    "        # Extract SNARK1 timing information\n",
    "        snark1_sent = beamsim.get_snark1_sent(items)\n",
    "        if snark1_sent and len(snark1_sent[0]) > 0:\n",
    "            snark1_completion_time = snark1_sent[0][-1] if snark1_sent[0] else 0\n",
    "            \n",
    "            # Get simulation info\n",
    "            _, _, validator_count, snark1_threshold, _ = beamsim.filter_report(items, \"info\")[0]\n",
    "            \n",
    "            return {\n",
    "                'topology': topology,\n",
    "                'topology_display': beamsim.topology_name[topology],\n",
    "                'parameter_name': parameter_name,\n",
    "                'parameter_value': param_value,\n",
    "                'parameter_display': param_display,\n",
    "                'snark1_completion_time': snark1_completion_time,\n",
    "                'validator_count': validator_count,\n",
    "                'snark1_threshold': snark1_threshold,\n",
    "                'success': True\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'topology': topology,\n",
    "                'parameter_name': parameter_name,\n",
    "                'parameter_value': param_value,\n",
    "                'parameter_display': param_display,\n",
    "                'success': False,\n",
    "                'error': 'No SNARK1 data found'\n",
    "            }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'topology': topology,\n",
    "            'parameter_name': parameter_name,\n",
    "            'parameter_value': param_value,\n",
    "            'parameter_display': param_display,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "def theoretical_minimum_snark1_time(validator_count, snark1_threshold, signature_size, sig_agg_rate, max_bitrate):\n",
    "    \"\"\"\n",
    "    Calculate the theoretical minimum SNARK1 aggregation time based on parameters.\n",
    "    \n",
    "    Args:\n",
    "        validator_count: Total number of validators\n",
    "        snark1_threshold: Threshold for SNARK1 generation (0-1)\n",
    "        signature_size: Size of each signature in bytes\n",
    "        sig_agg_rate: Rate of signature aggregation per second\n",
    "        max_bitrate: Maximum bandwidth in bytes per second (None for unlimited)\n",
    "        \n",
    "    Returns:\n",
    "        Theoretical minimum SNARK1 aggregation time in milliseconds\n",
    "    \"\"\"\n",
    "    if max_bitrate is None:\n",
    "        max_bitrate = float('inf')  # No limit\n",
    "    \n",
    "    # Calculate total data size to aggregate\n",
    "    total_data_size = validator_count * signature_size * snark1_threshold  # in bytes\n",
    "\n",
    "    # Calculate time to aggregate at the given rate\n",
    "    agg_time_sec = validator_count * snark1_threshold  / sig_agg_rate  # in seconds\n",
    "\n",
    "    # Calculate time based on bandwidth limit\n",
    "    bandwidth_time_sec = total_data_size / max_bitrate  # in seconds\n",
    "    \n",
    "    min_time_sec = agg_time_sec + bandwidth_time_sec\n",
    "    \n",
    "    return min_time_sec * 1000  # Convert to milliseconds\n",
    "\n",
    "def run_parameter_analysis(parameter_name, parameter_values, topologies=[\"gossip\", \"grid\"], \n",
    "                          display_name=None, display_unit=\"\", parallel=True, max_workers=None, \n",
    "                          **base_config):\n",
    "    \"\"\"\n",
    "    Generic function to analyze the effect of changing a parameter on SNARK1 aggregation time.\n",
    "    \n",
    "    Args:\n",
    "        parameter_name: Name of the parameter to vary (e.g., 'signature_size', 'mesh_n')\n",
    "        parameter_values: List of values to test for the parameter\n",
    "        topologies: List of network topologies to test\n",
    "        display_name: Human-readable name for the parameter (defaults to parameter_name)\n",
    "        display_unit: Unit to display after the parameter value (e.g., \"KB\", \"Mbps\")\n",
    "        parallel: Whether to run simulations in parallel (default: True)\n",
    "        max_workers: Maximum number of parallel workers (default: min(8, cpu_count()))\n",
    "        **base_config: Base configuration parameters and run kwargs\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with results, with parameter order preserved\n",
    "    \"\"\"\n",
    "    \n",
    "    if display_name is None:\n",
    "        display_name = parameter_name.replace('_', ' ').title()\n",
    "    \n",
    "    # Separate run kwargs from config overrides\n",
    "    run_kwargs_keys = {'mpi', 'c', 'b', 'g', 'gv', 'la', 'ga', 'shuffle', 't', 'local_aggregation_only'}\n",
    "    run_kwargs = {k: v for k, v in base_config.items() if k in run_kwargs_keys}\n",
    "    config_overrides = {k: v for k, v in base_config.items() if k not in run_kwargs_keys}\n",
    "    \n",
    "    # Determine the number of workers (use ThreadPoolExecutor which works better in Jupyter)\n",
    "    if max_workers is None:\n",
    "        max_workers = min(8, len(parameter_values) * len(topologies))  # Conservative default\n",
    "    \n",
    "    print(f\"Testing {display_name}: {parameter_values}\")\n",
    "    print(f\"Topologies: {topologies}\")\n",
    "    \n",
    "    if parallel:\n",
    "        print(f\"Running simulations in parallel with {max_workers} workers (ThreadPoolExecutor)...\\n\")\n",
    "    else:\n",
    "        print(\"Running simulations sequentially...\\n\")\n",
    "    \n",
    "    # Prepare all simulation parameters\n",
    "    simulation_params = []\n",
    "    for topology in topologies:\n",
    "        for param_value in parameter_values:\n",
    "            param_display = f\"{param_value} {display_unit}\".strip() if param_value is not None else \"Default/Unlimited\"\n",
    "            simulation_params.append((\n",
    "                topology, param_value, parameter_name, param_display,\n",
    "                config_overrides, run_kwargs, display_name, display_unit\n",
    "            ))\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    if parallel and len(simulation_params) > 1:\n",
    "        # Run simulations in parallel using ThreadPoolExecutor\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            # Submit all tasks\n",
    "            future_to_params = {}\n",
    "            for params in simulation_params:\n",
    "                topology, param_value, parameter_name, param_display, config_overrides, run_kwargs, display_name, display_unit = params\n",
    "                future = executor.submit(_run_single_simulation_thread, \n",
    "                                       topology, param_value, parameter_name, param_display,\n",
    "                                       config_overrides, run_kwargs, display_name, display_unit)\n",
    "                future_to_params[future] = params\n",
    "            \n",
    "            # Process completed tasks\n",
    "            total_sims = len(simulation_params)\n",
    "            completed = 0\n",
    "            \n",
    "            for future in as_completed(future_to_params):\n",
    "                completed += 1\n",
    "                result = future.result()\n",
    "                \n",
    "                if result['success']:\n",
    "                    results.append(result)\n",
    "                    topology_display = beamsim.topology_name.get(result['topology'], result['topology'])\n",
    "                    print(f\"  [{completed}/{total_sims}] {topology_display} - {result['parameter_display']}: \"\n",
    "                          f\"{result['snark1_completion_time']:.1f} ms\")\n",
    "                else:\n",
    "                    print(f\"  [{completed}/{total_sims}] ERROR - {result['topology']} - {result['parameter_display']}: \"\n",
    "                          f\"{result['error']}\")\n",
    "    else:\n",
    "        # Run simulations sequentially (original behavior)\n",
    "        for i, params in enumerate(simulation_params):\n",
    "            topology, param_value, parameter_name, param_display, config_overrides, run_kwargs, display_name, display_unit = params\n",
    "            print(f\"  [{i+1}/{len(simulation_params)}] Testing {topology} - {param_display}\")\n",
    "            \n",
    "            result = _run_single_simulation_thread(\n",
    "                topology, param_value, parameter_name, param_display,\n",
    "                config_overrides, run_kwargs, display_name, display_unit\n",
    "            )\n",
    "            \n",
    "            if result['success']:\n",
    "                results.append(result)\n",
    "                print(f\"    → {result['snark1_completion_time']:.1f} ms\")                \n",
    "            else:\n",
    "                    print(f\"    → ERROR: {result['error']}\")\n",
    "    \n",
    "    # Convert to DataFrame and preserve parameter order\n",
    "    df = pd.DataFrame(results)\n",
    "    if not df.empty:\n",
    "        # Add an order column to preserve the original parameter order\n",
    "        param_to_order = {param: i for i, param in enumerate(parameter_values)}\n",
    "        df['parameter_order'] = df['parameter_value'].map(param_to_order)\n",
    "        # Sort by topology and parameter order to ensure consistent ordering\n",
    "        df = df.sort_values(['topology', 'parameter_order']).reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_parameter_analysis(results_df, parameter_name, display_name=None, display_unit=\"\", \n",
    "                          title_suffix=\"\", figure_size=(14, 8), include_theoretical=True,\n",
    "                          **base_config):\n",
    "    \"\"\"\n",
    "    Plot the results of a parameter analysis.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame from run_parameter_analysis\n",
    "        parameter_name: Name of the parameter that was varied\n",
    "        display_name: Human-readable name for the parameter\n",
    "        display_unit: Unit for the parameter\n",
    "        title_suffix: Additional text for the plot title\n",
    "        figure_size: Size of the plot figure\n",
    "        include_theoretical: Whether to include theoretical minimum line\n",
    "        **base_config: Base configuration parameters for theoretical calculations\n",
    "    \"\"\"\n",
    "    \n",
    "    if display_name is None:\n",
    "        display_name = parameter_name.replace('_', ' ').title()\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=figure_size)\n",
    "    \n",
    "    # Plot lines for each topology\n",
    "    topologies = results_df['topology'].unique()\n",
    "    colors = sns.color_palette(\"husl\", len(topologies))\n",
    "    \n",
    "    # Get parameter order from the dataframe (preserves original input order)\n",
    "    if 'parameter_order' in results_df.columns:\n",
    "        # Use the preserved order\n",
    "        ordered_params = results_df.sort_values('parameter_order')['parameter_display'].unique()\n",
    "    else:\n",
    "        # Fallback to original behavior\n",
    "        ordered_params = results_df['parameter_display'].unique()\n",
    "    \n",
    "    for i, topology in enumerate(topologies):\n",
    "        topo_data = results_df[results_df['topology'] == topology].copy()\n",
    "        \n",
    "        # Sort by parameter order to maintain input sequence\n",
    "        if 'parameter_order' in topo_data.columns:\n",
    "            topo_data = topo_data.sort_values('parameter_order')\n",
    "        else:\n",
    "            # Fallback: try to sort by parameter value if numeric\n",
    "            try:\n",
    "                topo_data = topo_data.sort_values('parameter_value')\n",
    "            except:\n",
    "                pass  # Keep original order if sorting fails\n",
    "        \n",
    "        x_values = list(range(len(topo_data)))\n",
    "        y_values = topo_data['snark1_completion_time'].tolist()\n",
    "        \n",
    "        plt.plot(\n",
    "            x_values,\n",
    "            y_values,\n",
    "            marker='o',\n",
    "            linewidth=3,\n",
    "            markersize=8,\n",
    "            color=colors[i],\n",
    "            label=f'{topo_data.iloc[0][\"topology_display\"]} Topology',\n",
    "            alpha=0.8\n",
    "        )\n",
    "    \n",
    "    # Add theoretical minimum line if requested\n",
    "    if include_theoretical and len(results_df) > 0:\n",
    "        # Get default parameters for theoretical calculation\n",
    "        # Use the global DEFAULT_CONFIG as the base for theoretical calculations\n",
    "        theoretical_params = {**DEFAULT_CONFIG, **base_config}\n",
    "        \n",
    "        # Convert max_bitrate to bytes per second if it's a string\n",
    "        max_bitrate = theoretical_params['max_bitrate']\n",
    "        if isinstance(max_bitrate, str) and max_bitrate.endswith('Mbps'):\n",
    "            max_bitrate_mbps = float(max_bitrate[:-4])\n",
    "            max_bitrate_bps = max_bitrate_mbps * 1024 * 1024 / 8  # Convert Mbps to bytes/sec\n",
    "        elif max_bitrate is None:\n",
    "            max_bitrate_bps = None\n",
    "        else:\n",
    "            max_bitrate_bps = max_bitrate\n",
    "        \n",
    "        # Calculate total validator count (group_count * group_validator_count)\n",
    "        total_validator_count = theoretical_params['group_validator_count']\n",
    "        \n",
    "        # Calculate theoretical minimum times for each parameter value\n",
    "        theoretical_times = []\n",
    "        sample_data = results_df.sort_values('parameter_order' if 'parameter_order' in results_df.columns else 'parameter_value')\n",
    "        unique_param_values = sample_data['parameter_value'].unique()\n",
    "        \n",
    "        for param_value in unique_param_values:\n",
    "            # Update the parameter being analyzed\n",
    "            current_params = theoretical_params.copy()\n",
    "            current_params[parameter_name] = param_value\n",
    "            \n",
    "            # Handle special cases for parameter-specific calculations\n",
    "            if parameter_name == 'max_bitrate':\n",
    "                if isinstance(param_value, str) and param_value.endswith('Mbps'):\n",
    "                    max_bitrate_mbps = float(param_value[:-4])\n",
    "                    current_max_bitrate = max_bitrate_mbps * 1024 * 1024 / 8\n",
    "                elif param_value is None:\n",
    "                    current_max_bitrate = None\n",
    "                else:\n",
    "                    current_max_bitrate = param_value\n",
    "            else:\n",
    "                current_max_bitrate = max_bitrate_bps\n",
    "            \n",
    "            # Recalculate total validator count if group parameters changed\n",
    "            if parameter_name in ['group_count', 'group_validator_count']:\n",
    "                current_total_validators = current_params['group_validator_count']\n",
    "            else:\n",
    "                current_total_validators = total_validator_count\n",
    "            \n",
    "            theoretical_time = theoretical_minimum_snark1_time(\n",
    "                validator_count=current_total_validators,\n",
    "                snark1_threshold=current_params['snark1_threshold'],\n",
    "                signature_size=current_params['signature_size'],\n",
    "                sig_agg_rate=current_params['aggregation_rate_per_sec'],\n",
    "                max_bitrate=current_max_bitrate\n",
    "            )\n",
    "            theoretical_times.append(theoretical_time)\n",
    "        \n",
    "        # Plot theoretical minimum line\n",
    "        x_values = list(range(len(theoretical_times)))\n",
    "        plt.plot(\n",
    "            x_values,\n",
    "            theoretical_times,\n",
    "            linestyle='--',\n",
    "            linewidth=2,\n",
    "            color='red',\n",
    "            label='Theoretical Minimum',\n",
    "            alpha=0.8\n",
    "        )\n",
    "    \n",
    "    # Set axis labels and title\n",
    "    plt.xlabel(f'{display_name} {display_unit}'.strip(), fontweight='bold', fontsize=12)\n",
    "    plt.ylabel('SNARK1 Aggregation Time (ms)', fontweight='bold', fontsize=12)\n",
    "    \n",
    "    title = f'Effect of {display_name} on SNARK1 Aggregation Time'\n",
    "    if title_suffix:\n",
    "        title += f'\\n{title_suffix}'\n",
    "    title += '\\n(Local Aggregation Only Mode)'\n",
    "    plt.title(title, fontweight='bold', fontsize=14)\n",
    "    \n",
    "    # Set x-axis tick labels using preserved parameter order\n",
    "    plt.xticks(range(len(ordered_params)), ordered_params, rotation=45)\n",
    "    \n",
    "    plt.legend(frameon=True, fancybox=True, shadow=True, fontsize=11)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add performance annotations\n",
    "    if len(results_df) > 0:\n",
    "        min_time = results_df['snark1_completion_time'].min()\n",
    "        max_time = results_df['snark1_completion_time'].max()\n",
    "        time_diff = max_time - min_time\n",
    "        improvement = (time_diff / max_time) * 100\n",
    "        \n",
    "        plt.text(0.02, 0.98, \n",
    "                f'Max time difference: {time_diff:.1f}ms\\n'\n",
    "                f'Performance improvement: {improvement:.1f}%',\n",
    "                transform=plt.gca().transAxes,\n",
    "                verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8),\n",
    "                fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"{display_name.upper()} EFFECT SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Print theoretical minimum information if included\n",
    "    if include_theoretical and len(results_df) > 0:\n",
    "        print(f\"\\nTheoretical Minimum:\")\n",
    "        print(f\"  SNARK1 time range: {min(theoretical_times):.1f} - {max(theoretical_times):.1f} ms\")\n",
    "        print(f\"  Time difference: {max(theoretical_times) - min(theoretical_times):.1f} ms\")\n",
    "        \n",
    "        # Show theoretical minimum for each parameter value\n",
    "        sample_data = results_df.sort_values('parameter_order' if 'parameter_order' in results_df.columns else 'parameter_value')\n",
    "        unique_param_displays = sample_data['parameter_display'].unique()\n",
    "        for i, param_display in enumerate(unique_param_displays):\n",
    "            print(f\"    {param_display:>12}: {theoretical_times[i]:.1f} ms\")\n",
    "    \n",
    "    for topology in topologies:\n",
    "        topo_data = results_df[results_df['topology'] == topology]\n",
    "        if len(topo_data) > 0:\n",
    "            print(f\"\\n{topo_data.iloc[0]['topology_display']} Topology:\")\n",
    "            print(f\"  SNARK1 time range: {topo_data['snark1_completion_time'].min():.1f} - {topo_data['snark1_completion_time'].max():.1f} ms\")\n",
    "            print(f\"  Time difference: {topo_data['snark1_completion_time'].max() - topo_data['snark1_completion_time'].min():.1f} ms\")\n",
    "            \n",
    "            # Show performance for each parameter value\n",
    "            for _, row in topo_data.iterrows():\n",
    "                print(f\"    {row['parameter_display']:>12}: {row['snark1_completion_time']:.1f} ms\")\n",
    "\n",
    "\n",
    "def analyze_parameter_effect(parameter_name, parameter_values, topologies=[\"gossip\", \"grid\"], \n",
    "                           display_name=None, display_unit=\"\", title_suffix=\"\", \n",
    "                           parallel=True, max_workers=None, **base_config):\n",
    "    \"\"\"\n",
    "    Complete analysis workflow: run simulations and plot results.\n",
    "    \n",
    "    Args:\n",
    "        parameter_name: Name of the parameter to vary\n",
    "        parameter_values: List of values to test\n",
    "        topologies: List of topologies to test\n",
    "        display_name: Human-readable parameter name\n",
    "        display_unit: Unit for the parameter\n",
    "        title_suffix: Additional text for plot title\n",
    "        parallel: Whether to run simulations in parallel (default: True)\n",
    "        max_workers: Maximum number of parallel workers (default: cpu_count())\n",
    "        **base_config: Base configuration and run parameters\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Run the analysis\n",
    "    results_df = run_parameter_analysis(\n",
    "        parameter_name, parameter_values, topologies, \n",
    "        display_name, display_unit, parallel=parallel, \n",
    "        max_workers=max_workers, **base_config\n",
    "    )\n",
    "    \n",
    "    # Plot the results\n",
    "    plot_parameter_analysis(\n",
    "        results_df, parameter_name, display_name, \n",
    "        display_unit, title_suffix, **base_config\n",
    "    )\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe08729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_signature_size_effect(signature_sizes, topologies=[\"gossip\", \"grid\"], \n",
    "                                 parallel=True, max_workers=None, **base_config):\n",
    "    \"\"\"\n",
    "    Analyze how signature size affects SNARK1 aggregation time using the refactored framework.\n",
    "    \n",
    "    Args:\n",
    "        signature_sizes: List of signature sizes to test (in bytes)\n",
    "        topologies: List of network topologies to test\n",
    "        parallel: Whether to run simulations in parallel (default: True)\n",
    "        max_workers: Maximum number of parallel workers (default: cpu_count())\n",
    "        **base_config: Base configuration parameters\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with results\n",
    "    \"\"\"\n",
    "    return analyze_parameter_effect(\n",
    "        parameter_name='signature_size',\n",
    "        parameter_values=signature_sizes,\n",
    "        topologies=topologies,\n",
    "        display_name='Signature Size',\n",
    "        display_unit='bytes',\n",
    "        title_suffix='',\n",
    "        parallel=parallel,\n",
    "        max_workers=max_workers,\n",
    "        **base_config\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee17544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_bandwidth_effect(bandwidth_limits, signature_size=3072, topologies=[\"gossip\", \"grid\"], \n",
    "                            parallel=True, max_workers=None, **base_config):\n",
    "    \"\"\"\n",
    "    Analyze how max incoming bandwidth affects SNARK1 aggregation time using the refactored framework.\n",
    "    \n",
    "    Args:\n",
    "        bandwidth_limits: List of bandwidth limits to test (in Mbps, None for unlimited)\n",
    "        signature_size: Fixed signature size to use (in bytes)\n",
    "        topologies: List of network topologies to test\n",
    "        parallel: Whether to run simulations in parallel (default: True)\n",
    "        max_workers: Maximum number of parallel workers (default: cpu_count())\n",
    "        **base_config: Base configuration parameters\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with results\n",
    "    \"\"\"\n",
    "    # Convert bandwidth values to the format expected by the YAML config\n",
    "    bandwidth_values = []\n",
    "    for bw in bandwidth_limits:\n",
    "        if bw is None:\n",
    "            bandwidth_values.append(None)\n",
    "        else:\n",
    "            bandwidth_values.append(f\"{bw}Mbps\")\n",
    "    \n",
    "    return analyze_parameter_effect(\n",
    "        parameter_name='max_bitrate',\n",
    "        parameter_values=bandwidth_values,\n",
    "        topologies=topologies,\n",
    "        display_name='Max Incoming Bandwidth',\n",
    "        display_unit='',\n",
    "        title_suffix=f'Signature Size: {signature_size/1024:.1f} KB',\n",
    "        parallel=parallel,\n",
    "        max_workers=max_workers,\n",
    "        signature_size=signature_size,  # Fixed signature size\n",
    "        **base_config\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ef22b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_mesh_n_effect(mesh_n_values, topologies=[\"gossip\"], parallel=True, max_workers=None, **base_config):\n",
    "    \"\"\"\n",
    "    Analyze how mesh_n (gossip mesh size) affects SNARK1 aggregation time.\n",
    "    \n",
    "    Args:\n",
    "        mesh_n_values: List of mesh_n values to test\n",
    "        topologies: List of network topologies to test (typically just \"gossip\")\n",
    "        parallel: Whether to run simulations in parallel (default: True)\n",
    "        max_workers: Maximum number of parallel workers (default: cpu_count())\n",
    "        **base_config: Base configuration parameters\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with results\n",
    "    \"\"\"\n",
    "    return analyze_parameter_effect(\n",
    "        parameter_name='mesh_n',\n",
    "        parameter_values=mesh_n_values,\n",
    "        topologies=topologies,\n",
    "        display_name='Mesh N',\n",
    "        display_unit='peers',\n",
    "        title_suffix='Gossip Network Configuration',\n",
    "        parallel=parallel,\n",
    "        max_workers=max_workers,\n",
    "        **base_config\n",
    "    )\n",
    "\n",
    "\n",
    "def analyze_non_mesh_n_effect(non_mesh_n_values, topologies=[\"gossip\"], parallel=True, max_workers=None, **base_config):\n",
    "    \"\"\"\n",
    "    Analyze how non_mesh_n (gossip non-mesh connections) affects SNARK1 aggregation time.\n",
    "    \n",
    "    Args:\n",
    "        non_mesh_n_values: List of non_mesh_n values to test\n",
    "        topologies: List of network topologies to test (typically just \"gossip\")\n",
    "        parallel: Whether to run simulations in parallel (default: True)\n",
    "        max_workers: Maximum number of parallel workers (default: cpu_count())\n",
    "        **base_config: Base configuration parameters\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with results\n",
    "    \"\"\"\n",
    "    return analyze_parameter_effect(\n",
    "        parameter_name='non_mesh_n',\n",
    "        parameter_values=non_mesh_n_values,\n",
    "        topologies=topologies,\n",
    "        display_name='Non-Mesh N',\n",
    "        display_unit='peers',\n",
    "        title_suffix='Gossip Network Configuration',\n",
    "        parallel=parallel,\n",
    "        max_workers=max_workers,\n",
    "        **base_config\n",
    "    )\n",
    "\n",
    "\n",
    "def analyze_group_validator_count_effect(validator_counts, topologies=[\"gossip\", \"grid\"], \n",
    "                                       parallel=True, max_workers=None, **base_config):\n",
    "    \"\"\"\n",
    "    Analyze how group_validator_count affects SNARK1 aggregation time.\n",
    "    \n",
    "    Args:\n",
    "        validator_counts: List of validator counts per group to test\n",
    "        topologies: List of network topologies to test\n",
    "        parallel: Whether to run simulations in parallel (default: True)\n",
    "        max_workers: Maximum number of parallel workers (default: cpu_count())\n",
    "        **base_config: Base configuration parameters\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with results\n",
    "    \"\"\"\n",
    "    return analyze_parameter_effect(\n",
    "        parameter_name='group_validator_count',\n",
    "        parameter_values=validator_counts,\n",
    "        topologies=topologies,\n",
    "        display_name='Group Validator Count',\n",
    "        display_unit='validators',\n",
    "        title_suffix='Network Scale Analysis',\n",
    "        parallel=parallel,\n",
    "        max_workers=max_workers,\n",
    "        **base_config\n",
    "    )\n",
    "\n",
    "\n",
    "def analyze_local_aggregator_count_effect(aggregator_counts, topologies=[\"gossip\", \"grid\"], \n",
    "                                        parallel=True, max_workers=None, **base_config):\n",
    "    \"\"\"\n",
    "    Analyze how group_local_aggregator_count affects SNARK1 aggregation time.\n",
    "    \n",
    "    Args:\n",
    "        aggregator_counts: List of local aggregator counts per group to test\n",
    "        topologies: List of network topologies to test\n",
    "        parallel: Whether to run simulations in parallel (default: True)\n",
    "        max_workers: Maximum number of parallel workers (default: cpu_count())\n",
    "        **base_config: Base configuration parameters\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with results\n",
    "    \"\"\"\n",
    "    return analyze_parameter_effect(\n",
    "        parameter_name='group_local_aggregator_count',\n",
    "        parameter_values=aggregator_counts,\n",
    "        topologies=topologies,\n",
    "        display_name='Local Aggregator Count',\n",
    "        display_unit='aggregators',\n",
    "        title_suffix='Aggregation Capacity Analysis',\n",
    "        parallel=parallel,\n",
    "        max_workers=max_workers,\n",
    "        **base_config\n",
    "    )\n",
    "\n",
    "\n",
    "def analyze_aggregation_rate_effect(aggregation_rates, topologies=[\"gossip\", \"grid\"], \n",
    "                                  parallel=True, max_workers=None, **base_config):\n",
    "    \"\"\"\n",
    "    Analyze how aggregation_rate_per_sec affects SNARK1 aggregation time.\n",
    "    \n",
    "    Args:\n",
    "        aggregation_rates: List of aggregation rates to test (signatures per second)\n",
    "        topologies: List of network topologies to test\n",
    "        parallel: Whether to run simulations in parallel (default: True)\n",
    "        max_workers: Maximum number of parallel workers (default: cpu_count())\n",
    "        **base_config: Base configuration parameters\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with results\n",
    "    \"\"\"\n",
    "    return analyze_parameter_effect(\n",
    "        parameter_name='aggregation_rate_per_sec',\n",
    "        parameter_values=aggregation_rates,\n",
    "        topologies=topologies,\n",
    "        display_name='Aggregation Rate',\n",
    "        display_unit='sig/sec',\n",
    "        title_suffix='Processing Speed Analysis',\n",
    "        parallel=parallel,\n",
    "        max_workers=max_workers,\n",
    "        **base_config\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308510c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "topologies = [\"gossip\", \"grid\"]\n",
    "\n",
    "# Signature Size Analysis - Using the refactored approach\n",
    "# This demonstrates how the new framework simplifies the analysis process\n",
    "\n",
    "# Test different signature sizes to analyze their effect on SNARK1 aggregation time\n",
    "signature_sizes = [\n",
    "    96,      # 96 bytes - very small signature (BLS)\n",
    "    1024,    # 1 KB - small signature\n",
    "    2048,    # 2 KB - medium-small signature  \n",
    "    3072,    # 3 KB - default signature size\n",
    "    4096,    # 4 KB - medium signature\n",
    "]\n",
    "\n",
    "# Base configuration parameters\n",
    "base_config = {\n",
    "    'mpi': False,  # Use MPI for faster simulations\n",
    "    # Add any other base parameters you want to override\n",
    "}\n",
    "\n",
    "# Test on both gossip and grid topologies\n",
    "topologies = [\"gossip\", \"grid\"]\n",
    "\n",
    "print(\"Analyzing the effect of signature size on SNARK1 aggregation time...\")\n",
    "print(\"Using the refactored analysis framework for cleaner code.\\n\")\n",
    "\n",
    "# Run the signature size effect analysis using the new framework\n",
    "results_df = analyze_signature_size_effect(signature_sizes, topologies, max_workers=5, **base_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c17057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the effect of max incoming bandwidth on SNARK1 aggregation time\n",
    "# Test different bandwidth limits to understand network bottlenecks\n",
    "\n",
    "bandwidth_limits = [\n",
    "    5,      # 5 Mbps - Low bandwidth\n",
    "    10,     # 10 Mbps - Medium-low bandwidth\n",
    "    25,     # 25 Mbps - Medium bandwidth\n",
    "    50,     # 50 Mbps - High bandwidth\n",
    "    100,    # 100 Mbps - Very high bandwidth\n",
    "    200,    # 200 Mbps - Extremely high bandwidth\n",
    "    None,   # No limit - Unlimited bandwidth\n",
    "]\n",
    "\n",
    "# Use fixed signature size of 3072 bytes (3KB) as requested\n",
    "signature_size = 3072\n",
    "\n",
    "# Base configuration parameters\n",
    "base_config = {\n",
    "    'mpi': False,  # Use MPI for faster simulations\n",
    "}\n",
    "\n",
    "# Test on both gossip and grid topologies\n",
    "topologies = [\"gossip\", \"grid\"]\n",
    "\n",
    "print(\"Analyzing the effect of max incoming bandwidth on SNARK1 aggregation time...\")\n",
    "print(f\"Using fixed signature size: {signature_size} bytes ({signature_size/1024:.1f} KB)\")\n",
    "print(\"Using the refactored analysis framework.\\n\")\n",
    "\n",
    "# Run the bandwidth effect analysis using the new framework\n",
    "bandwidth_results_df = analyze_bandwidth_effect(bandwidth_limits, signature_size, topologies, max_workers=5, **base_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daf94de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example analyses for new parameters using the refactored framework\n",
    "# These demonstrate how easy it is to analyze different parameters\n",
    "\n",
    "# Example 1: Analyze mesh_n effect (gossip network mesh size)\n",
    "print(\"=\"*60)\n",
    "print(\"EXAMPLE 1: Mesh N Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "mesh_n_values = [4, 6, 8, 10, 12]  # Different mesh sizes\n",
    "base_config = {'mpi': False, 'signature_size': 3072}\n",
    "\n",
    "mesh_n_results = analyze_mesh_n_effect(mesh_n_values, topologies=[\"gossip\"], max_workers=5, **base_config)\n",
    "\n",
    "\n",
    "# Example 2: Analyze non_mesh_n effect (gossip non-mesh connections)\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"EXAMPLE 2: Non-Mesh N Analysis\")\n",
    "# print(\"=\"*60)\n",
    "\n",
    "# non_mesh_n_values = [2, 4, 6, 8, 10]  # Different non-mesh connection counts\n",
    "# base_config = {'mpi': False, 'signature_size': 3072}\n",
    "\n",
    "# non_mesh_n_results = analyze_non_mesh_n_effect(non_mesh_n_values, topologies=[\"gossip\"], max_workers=5, **base_config)\n",
    "\n",
    "\n",
    "# Example 3: Analyze group_validator_count effect (network scale)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXAMPLE 3: Group Validator Count Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "validator_counts = [128, 256, 512, 768, 1024]  # Different validator counts per group\n",
    "base_config = {'mpi': False, 'signature_size': 3072}\n",
    "\n",
    "validator_count_results = analyze_group_validator_count_effect(validator_counts, topologies=[\"gossip\", \"grid\"], **base_config)\n",
    "\n",
    "\n",
    "# Example 4: Analyze local aggregator count effect\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXAMPLE 4: Local Aggregator Count Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "aggregator_counts = [\"1%\", \"10%\", \"25%\", \"50%\"]  # Different local aggregator counts\n",
    "base_config = {'mpi': False, 'signature_size': 3072}\n",
    "\n",
    "aggregator_count_results = analyze_local_aggregator_count_effect(aggregator_counts, topologies=[\"gossip\", \"grid\"], max_workers=5, **base_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beamsim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
